spec is "1.0"

capabilities:
  uploads

policy
  allow ingestion.run
  allow ingestion.review
  require ingestion.override with ingestion.override
  require ingestion.skip with ingestion.skip
  require retrieval.include_warn with retrieval.include_warn
  require upload.replace with upload.replace

record "Document":
  field "document_id" is text must be present
  field "title" is text must be present
  field "upload_id" is text must be present
  field "status" is text must be present
  field "quality" is text must be present

record "DocumentChange":
  field "document_id" is text must be present
  field "event" is text must be present
  field "upload_id" is text must be present
  field "previous_upload_id" is text must be present
  field "status" is text must be present
  field "chunk_ids" is json must be present

record "RetrievalReport":
  field "query" is text must be present
  field "result_count" is number must be present
  field "preferred_quality" is text must be present
  field "warn_allowed" is boolean must be present
  field "included_warn" is boolean must be present
  field "coverage" is number must be present
  field "limit" is number must be present

record "Citation":
  field "query" is text must be present
  field "document_id" is text must be present
  field "chunk_id" is text must be present
  field "title" is text must be present
  field "source_id" is text must be present
  field "snippet" is text must be present

record "Answer":
  field "query" is text must be present
  field "response" is text must be present
  field "status" is text must be present
  field "confidence" is number must be present
  field "coverage" is number must be present
  field "source_count" is number must be present

record "ExplainEntry":
  field "stage" is text must be present
  field "detail" is json must be present

flow "ingest_document": requires true
  let upload_id is ""
  let upload_name is ""
  let has_upload is false
  try:
    set upload_id is input.upload_id
    set has_upload is true
  with catch err:
    set has_upload is false
  if has_upload is false:
    try:
      let uploads is state.uploads.intake
      let count is list length of uploads
      if count is greater than 0:
        let last_index is count - 1
        let recent_upload is list get uploads at last_index
        set upload_id is recent_upload.id
        set upload_name is recent_upload.name
        set has_upload is true
    with catch err:
      set has_upload is false
  if has_upload is false or upload_id is "":
    return map:
      "status" is "no_upload"

  let doc_id is ""
  let doc_title is ""
  let has_document is false
  try:
    set doc_id is input.document_id
    set has_document is true
  with catch err:
    set has_document is false
  if has_document is false or doc_id is "":
    set doc_id is upload_id
    set has_document is true

  let has_title is false
  try:
    set doc_title is input.title
    set has_title is true
  with catch err:
    set has_title is false
  if has_title is false or doc_title is "":
    set has_title is false
  if has_title is false and upload_name is not "":
    set doc_title is upload_name
    set has_title is true
  if has_title is false:
    set doc_title is doc_id

  find "Document" where document_id is doc_id
  let doc_count is list length of document_results
  let has_existing is doc_count is greater than 0
  let previous_upload_id is ""
  if has_existing:
    let last_index is doc_count - 1
    let existing_doc is list get document_results at last_index
    set previous_upload_id is existing_doc.upload_id

  let out is call pipeline "ingestion":
    input:
      upload_id is upload_id
    output:
      report
      ingestion
      index
  let report is out.report
  let status is report.status
  let reasons is report.reasons
  let ingest_status is status
  let new_upload_id is upload_id

  let chunk_ids is list:
  if status is not "block":
    let index is out.index
    let chunks is index.chunks
    let doc_chunks is filter chunks with item as chunk:
      chunk.upload_id is upload_id
    set chunk_ids is map doc_chunks with item as chunk:
      chunk.chunk_id

  let event is "new"
  if status is "block":
    set event is "reject"
  if status is not "block" and has_existing:
    set event is "update"

  let index_updated is status is not "block"
  if status is not "block":
    if has_existing:
      update "Document" where document_id is doc_id set:
        "title" is doc_title
        upload_id is new_upload_id
        status is "active"
        quality is ingest_status
      if previous_upload_id is not "" and previous_upload_id is not equal to upload_id:
        try:
          let index is state.index
          let chunks is index.chunks
          let kept_chunks is filter chunks with item as chunk:
            chunk.upload_id is not equal to previous_upload_id
          let updated_index is map set index key "chunks" value kept_chunks
          set state.index is updated_index
        with catch err:
          set index_updated is false
    else:
      set state.document with:
        document_id is doc_id
        title is doc_title
        upload_id is upload_id
        status is "active"
        quality is status
      create "Document" with state.document as document

  if status is "block" and has_existing is false:
    set state.document with:
      document_id is doc_id
      title is doc_title
      upload_id is upload_id
      status is "rejected"
      quality is status
    create "Document" with state.document as document

  set state.change_record with:
    document_id is doc_id
    event is event
    upload_id is upload_id
    previous_upload_id is previous_upload_id
    status is status
    chunk_ids is chunk_ids
  create "DocumentChange" with state.change_record as change

  set state.explain_entry with:
    stage is "ingestion"
    detail is map:
      "document_id" is doc_id
      "upload_id" is upload_id
      "previous_upload_id" is previous_upload_id
      "event" is event
      "status" is status
      "reasons" is reasons
      "chunk_ids" is chunk_ids
      "index_updated" is index_updated
  create "ExplainEntry" with state.explain_entry as explain

  return map:
    "status" is event
    "document_id" is doc_id
    "upload_id" is upload_id

flow "remove_document": requires true
  let doc_id is ""
  let has_document is false
  try:
    set doc_id is input.document_id
    set has_document is true
  with catch err:
    set has_document is false
  if has_document is false:
    find "Document" where true
    let count is list length of document_results
    if count is 0:
      return map:
        "status" is "no_document"
    let last_index is count - 1
    let last_doc is list get document_results at last_index
    set doc_id is last_doc.document_id

  find "Document" where document_id is doc_id
  let count is list length of document_results
  if count is 0:
    return map:
      "status" is "missing_document"
  let last_index is count - 1
  let existing_doc is list get document_results at last_index
  let upload_id is existing_doc.upload_id
  let quality is existing_doc.quality

  let chunks is list:
  try:
    let index is state.index
    set chunks is index.chunks
  with catch err:
    set chunks is list:

  let doc_chunks is filter chunks with item as chunk:
    chunk.upload_id is upload_id
  let chunk_ids is map doc_chunks with item as chunk:
    chunk.chunk_id

  let index_updated is true
  try:
    let kept_chunks is filter chunks with item as chunk:
      chunk.upload_id is not equal to upload_id
    let updated_index is map set state.index key "chunks" value kept_chunks
    set state.index is updated_index
  with catch err:
    set index_updated is false

  update "Document" where document_id is doc_id set:
    status is "removed"
    quality is quality

  set state.change_record with:
    document_id is doc_id
    event is "remove"
    upload_id is upload_id
    previous_upload_id is ""
    status is "removed"
    chunk_ids is chunk_ids
  create "DocumentChange" with state.change_record as change

  set state.explain_entry with:
    stage is "remove"
    detail is map:
      "document_id" is doc_id
      "upload_id" is upload_id
      "event" is "remove"
      "status" is "removed"
      "chunk_ids" is chunk_ids
      "index_updated" is index_updated
  create "ExplainEntry" with state.explain_entry as explain

  return map:
    "status" is "removed"
    "document_id" is doc_id
    "upload_id" is upload_id

flow "answer_query": requires true
  set state.chat.thinking is true
  let query is ""
  let has_query is false
  try:
    set query is input.query
    set has_query is true
  with catch err:
    set has_query is false
  if has_query is false:
    try:
      set query is input.message
      set has_query is true
    with catch err:
      set has_query is false
  if has_query is false:
    try:
      set query is input.values.query
      set has_query is true
    with catch err:
      set has_query is false

  if has_query is false or query is null or query is "":
    let messages is list:
      map:
        "role" is "assistant"
        "content" is "No query provided."
    set state.chat.messages is messages
    set state.chat.citations is list:
    set state.chat.thinking is false
    return map:
      "status" is "invalid_query"

  let limit is list length of list: 1, 1, 1, 1, 1, 1
  let out is call pipeline "retrieval":
    input:
      query is query
      limit is limit
    output:
      report
  let report is out.report
  let results is report.results
  let result_count is list length of results
  let coverage is result_count / limit
  let ranking_inputs is map results with item as result:
    result.chunk_id

  let citations is list:
  let sources is list:
  for each result in results:
    let doc_id is result.upload_id
    let source_title is result.upload_id
    find "Document" where upload_id is result.upload_id
    let doc_count is list length of document_results
    if doc_count is greater than 0:
      let last_index is doc_count - 1
      let doc is list get document_results at last_index
      set doc_id is doc.document_id
      set source_title is doc.title
    let source_id is result.chunk_id
    let snippet is result.text
    let citation is map:
      "title" is source_title
      "source_id" is source_id
      "snippet" is snippet
    set citations is list append citations with citation
    let source_entry is map:
      "document_id" is doc_id
      "upload_id" is result.upload_id
      "chunk_id" is source_id
      "quality" is result.quality
    set sources is list append sources with source_entry
    set state.citation_record with:
      query is query
      document_id is doc_id
      chunk_id is source_id
      title is source_title
      source_id is source_id
      snippet is snippet
    create "Citation" with state.citation_record as citation_record

  let response is "No answer available."
  let answer_status is "no_answer"
  if result_count is greater than 0:
    let first_result is list get results at 0
    set response is first_result.text
    set answer_status is "answered"

  let confidence is 0
  if answer_status is "answered":
    set confidence is coverage

  let messages is list:
    map:
      "role" is "user"
      "content" is query
    map:
      "role" is "assistant"
      "content" is response

  set state.chat.messages is messages
  set state.chat.citations is citations
  set state.chat.thinking is false

  set state.retrieval_record with:
    query is report.query
    result_count is result_count
    preferred_quality is report.preferred_quality
    warn_allowed is report.warn_allowed
    included_warn is report.included_warn
    coverage is coverage
    limit is limit
  create "RetrievalReport" with state.retrieval_record as retrieval_record

  set state.answer_record with:
    query is query
    response is response
    status is answer_status
    confidence is confidence
    coverage is coverage
    source_count is result_count
  create "Answer" with state.answer_record as answer

  set state.explain_entry with:
    stage is "retrieval"
    detail is map:
      "raw_query" is query
      "query" is report.query
      "limit" is limit
      "result_count" is result_count
      "preferred_quality" is report.preferred_quality
      "warn_allowed" is report.warn_allowed
      "included_warn" is report.included_warn
      "ranking" is map:
        "ordering" is "index_order"
        "tie_break" is "ingestion_order"
        "inputs" is ranking_inputs
        "scores" is list:
      "sources" is sources
  create "ExplainEntry" with state.explain_entry as explain

  set state.explain_entry with:
    stage is "evaluation"
    detail is map:
      "coverage" is coverage
      "faithfulness" is answer_status is "answered"
      "status" is answer_status
      "source_count" is result_count
  create "ExplainEntry" with state.explain_entry as explain

  return map:
    "status" is answer_status
    "query" is query
    "source_count" is result_count

page "Knowledge":
  purpose is "Deterministic ingestion, retrieval, and cited answers."
  title is "Knowledge Workspace"
  text is "Ingest documents, retrieve sources, and return cited answers."

  section "Ingestion":
    text is "Upload a file, then ingest it."
    upload intake
    button "Ingest latest":
      calls flow "ingest_document"
    table is "Document":
      columns:
        include document_id
        include `title`
        include status
        include quality
        include upload_id
      pagination:
        page_size is 10

  section "Query":
    text is "Ask a question; responses are grounded in retrieved sources."
    chat:
      messages from is state.chat.messages
      composer sends to flow "answer_query"
      thinking when is state.chat.thinking
      citations from is state.chat.citations
    table is "Answer":
      columns:
        include query
        include status
        include confidence
        include coverage
        include source_count
      pagination:
        page_size is 5

  section "Citations":
    table is "Citation":
      columns:
        include query
        include document_id
        include chunk_id
        include `title`
        include source_id
      pagination:
        page_size is 5

  section "Explain":
    table is "ExplainEntry":
      columns:
        include stage
        include detail
      pagination:
        page_size is 10
